---
description: Analyze decision quality with scenario testing, bias detection, and team decision-making process optimization.
category: team-collaboration
argument-hint: "Specify analysis criteria"
allowed-tools: Bash(gh *)
---

# Decision Quality Analyzer

Analyze decision quality with scenario testing, bias detection, and team decision-making process optimization.

## Instructions

You are tasked with systematically analyzing and improving team decision quality through scenario analysis, bias detection, and process optimization. Follow this approach: **$ARGUMENTS**

### 1. Decision Context Assessment

**Critical Decision Quality Context:**

- **Decision Type**: What category of decision are you analyzing?
- **Decision Process**: How does the team currently make this type of decision?
- **Stakeholders**: Who participates in and is affected by these decisions?
- **Success Metrics**: How do you measure decision quality and outcomes?
- **Historical Data**: What past decisions provide learning opportunities?

**If context is unclear, guide systematically:**

```
Missing Decision Type:
"What type of team decision needs quality analysis?
- Strategic Decisions: Product direction, market positioning, technology choices
- Operational Decisions: Process improvements, resource allocation, priority setting
- Personnel Decisions: Hiring, team structure, role assignments, performance management
- Technical Decisions: Architecture choices, tool selection, implementation approaches

Please specify the decision scope and typical complexity level."

Missing Decision Process:
"How does your team currently make these decisions?
- Individual Authority: Single decision maker with consultation
- Consensus Building: Group discussion until agreement is reached
- Majority Vote: Democratic process with formal or informal voting
- Delegated Authority: Decision rights assigned to specific roles or committees
- Data-Driven: Systematic analysis and evidence-based approaches"
```

### 2. Decision Quality Framework

**Systematic decision evaluation methodology:**

#### Quality Dimension Assessment
```
Multi-Dimensional Decision Quality:

Process Quality (25% weight):
- Information Gathering: Completeness and accuracy of data collection
- Stakeholder Involvement: Appropriate participation and perspective inclusion
- Alternative Generation: Creativity and comprehensiveness of option development
- Analysis Rigor: Systematic evaluation and trade-off assessment

Outcome Quality (25% weight):
- Goal Achievement: Success in reaching intended objectives
- Unintended Consequences: Management of secondary effects and side impacts
- Stakeholder Satisfaction: Acceptance and support from affected parties
- Long-term Sustainability: Durability and adaptability of decision outcomes

Timing Quality (25% weight):
- Decision Speed: Appropriate pace for urgency and complexity
- Information Timing: Optimal balance of speed vs additional information
- Implementation Timing: Coordination with market conditions and organizational readiness
- Review Timing: Appropriate schedule for decision assessment and adjustment

Learning Quality (25% weight):
- Knowledge Capture: Documentation and institutional learning
- Bias Recognition: Awareness and mitigation of cognitive biases
- Process Improvement: Methodology enhancement based on outcomes
- Capability Building: Team decision-making skill development
```

#### Decision Success Metrics
- Quantitative outcomes (financial, operational, performance metrics)
- Qualitative outcomes (satisfaction, engagement, strategic alignment)
- Process efficiency (time to decision, resource utilization)
- Learning outcomes (knowledge gained, capability developed)

### 3. Bias Detection and Mitigation

**Systematic cognitive bias identification:**

#### Common Decision Biases
```
Team Decision Bias Framework:

Individual Cognitive Biases:
- Confirmation Bias: Seeking information that supports preconceptions
- Anchoring Bias: Over-relying on first information received
- Availability Bias: Overweighting easily recalled examples
- Overconfidence Bias: Excessive certainty in judgment accuracy
- Sunk Cost Fallacy: Continuing failed approaches due to past investment

Group Decision Biases:
- Groupthink: Pressure for harmony reducing critical evaluation
- Risky Shift: Groups making riskier decisions than individuals
- Authority Bias: Deferring to hierarchy rather than evidence
- Social Proof: Following others' decisions without independent analysis
- Planning Fallacy: Systematic underestimation of time and resources

Organizational Biases:
- Status Quo Bias: Preferring current state over change
- Not Invented Here: Rejecting external ideas and solutions
- Survivorship Bias: Focusing only on successful cases
- Attribution Bias: Misattributing success and failure causes
- Political Bias: Decisions influenced by organizational politics
```

#### Bias Mitigation Strategies
```
Systematic Bias Reduction:

Process-Based Mitigation:
- Devil's Advocate: Designated critical evaluation role
- Red Team Analysis: Systematic challenge of assumptions and conclusions
- Diverse Perspectives: Multi-functional and multi-level input
- Anonymous Input: Reducing social pressure and hierarchy effects

Tool-Based Mitigation:
- Decision Trees: Systematic option evaluation and comparison
- Pre-mortem Analysis: Imagining failure scenarios and prevention
- Reference Class Forecasting: Using similar historical examples
- Outside View: External perspective and benchmarking

Cultural Mitigation:
- Psychological Safety: Encouraging dissent and critical thinking
- Learning Orientation: Celebrating learning from failures
- Evidence-Based Culture: Valuing data over intuition and politics
- Continuous Improvement: Regular process assessment and enhancement
```

### 4. Scenario-Based Decision Testing

**Test decision quality through hypothetical scenarios:**

#### Decision Scenario Framework
```
Comprehensive Decision Testing:

Historical Scenario Testing:
- Apply current decision process to past decisions
- Compare predicted vs actual outcomes
- Identify process improvements that would have helped
- Calibrate decision confidence and accuracy

Hypothetical Scenario Testing:
- Create realistic decision scenarios for practice
- Test team process under different conditions
- Identify process strengths and weaknesses
- Build team decision-making capability

Stress Test Scenarios:
- Time pressure and urgency constraints
- Incomplete information and high uncertainty
- Conflicting stakeholder interests and priorities
- High-stakes decisions with significant consequences

Learning Scenarios:
- Successful decision analysis and pattern recognition
- Failed decision post-mortem and lesson extraction
- Near-miss analysis and improvement identification
- Best practice sharing and capability transfer
```

#### Simulation-Based Improvement
- Role-playing exercises for complex decision scenarios
- Process experimentation with low-stakes decisions
- A/B testing of different decision methodologies
- Scenario planning for future decision situations

### 5. Team Decision Process Optimization

**Systematic improvement of decision-making workflows:**

#### Process Enhancement Framework
```
Decision Process Optimization:

Information Management:
- Data Collection: Systematic gathering of relevant information
- Information Quality: Accuracy, completeness, and timeliness assessment
- Bias Detection: Recognition of information source biases
- Knowledge Synthesis: Integration of diverse information sources

Stakeholder Engagement:
- Identification: Complete mapping of affected and influential parties
- Consultation: Systematic input gathering and perspective integration
- Communication: Clear explanation of process and decision rationale
- Buy-in: Building support and commitment for implementation

Analysis and Evaluation:
- Option Generation: Creative and comprehensive alternative development
- Criteria Definition: Clear success metrics and evaluation standards
- Trade-off Analysis: Systematic comparison of costs and benefits
- Risk Assessment: Identification and mitigation of potential problems

Decision Implementation:
- Planning: Detailed implementation strategy and timeline
- Resource Allocation: Appropriate staffing and budget assignment
- Monitoring: Progress tracking and outcome measurement
- Adaptation: Course correction based on results and learning
```

#### Team Capability Building
- Decision-making skill training and development
- Process facilitation and meeting effectiveness
- Critical thinking and analytical capability enhancement
- Communication and stakeholder management improvement

### 6. Output Generation and Recommendations

**Present decision quality insights in actionable format:**

```
## Decision Quality Analysis: [Decision Type/Process]

### Current State Assessment
- Decision Process Maturity: [evaluation of current methodology]
- Quality Dimension Scores: [process, outcome, timing, learning ratings]
- Bias Vulnerability: [key cognitive biases affecting decisions]
- Stakeholder Satisfaction: [feedback on decision process and outcomes]

### Key Findings

#### Decision Process Strengths:
- Effective Practices: [what works well in current process]
- Quality Outcomes: [successful decisions and positive patterns]
- Team Capabilities: [strong skills and effective behaviors]
- Stakeholder Engagement: [successful involvement and communication]

#### Improvement Opportunities:
- Process Gaps: [missing steps or inadequate methodology]
- Bias Vulnerabilities: [cognitive biases affecting decision quality]
- Information Deficits: [data gaps and analysis weaknesses]
- Implementation Challenges: [execution and follow-through issues]

### Optimization Recommendations

#### Immediate Improvements (0-30 days):
- Process Quick Fixes: [simple methodology enhancements]
- Bias Mitigation: [specific techniques for bias reduction]
- Tool Implementation: [decision aids and analytical frameworks]
- Communication Enhancement: [stakeholder engagement improvements]

#### Medium-term Development (1-6 months):
- Capability Building: [training and skill development programs]
- Process Standardization: [consistent methodology across decisions]
- Quality Measurement: [metrics and feedback systems]
- Cultural Development: [decision-making mindset and values]

#### Long-term Transformation (6+ months):
- Organizational Learning: [institutional knowledge and capability]
- Advanced Analytics: [data-driven decision support systems]
- Innovation Integration: [new methodologies and tools]
- Competitive Advantage: [decision-making as strategic capability]

### Success Metrics and Monitoring
- Decision Quality KPIs: [measurable indicators of improvement]
- Process Efficiency Metrics: [speed and resource utilization]
- Outcome Tracking: [business results and stakeholder satisfaction]
- Learning Indicators: [capability development and knowledge capture]

### Implementation Roadmap
- Phase 1: [immediate process improvements and bias mitigation]
- Phase 2: [capability building and measurement system]
- Phase 3: [advanced methodology and cultural transformation]
- Success Criteria: [specific goals and achievement measures]
```

### 7. Continuous Learning Integration

**Establish ongoing decision quality improvement:**

#### Decision Outcome Tracking
- Systematic monitoring of decision results and impacts
- Correlation analysis between process quality and outcomes
- Pattern recognition for successful vs unsuccessful decisions
- Feedback integration for process refinement and enhancement

#### Organizational Learning
- Best practice identification and knowledge sharing
- Decision case study development and team learning
- Cross-functional learning and capability transfer
- Industry benchmark comparison and competitive analysis

## Usage Examples

```bash
# Product strategy decision analysis
/team:decision-quality-analyzer Analyze product roadmap prioritization decisions for bias and process improvement opportunities

# Technical architecture decision assessment
/team:decision-quality-analyzer Evaluate technology stack decisions using scenario testing and stakeholder satisfaction analysis

# Hiring process decision optimization
/team:decision-quality-analyzer Optimize candidate evaluation and selection process through bias detection and outcome tracking

# Investment decision quality improvement
/team:decision-quality-analyzer Improve capital allocation decisions through process standardization and learning integration
```

## Quality Indicators

- **Green**: Comprehensive bias analysis, validated process improvements, outcome tracking
- **Yellow**: Basic bias recognition, some process enhancement, limited outcome measurement
- **Red**: Minimal bias awareness, ad-hoc process, no systematic improvement

## Common Pitfalls to Avoid

- Analysis paralysis: Over-analyzing decisions instead of improving decision-making
- Bias blindness: Not recognizing team and organizational cognitive biases
- Process rigidity: Creating inflexible procedures that slow appropriate decisions
- Outcome fixation: Judging process quality only by outcomes rather than methodology
- Individual focus: Ignoring group dynamics and organizational factors
- One-size-fits-all: Using same process for all decision types and contexts

Transform team decision-making from intuition-based guessing into systematic, evidence-driven capability that creates sustainable competitive advantage.
