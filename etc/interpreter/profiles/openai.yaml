# https://docs.openinterpreter.com/settings/all-settings

disable_telemetry: true

local: false
offline: false # uses https://api.openinterpreter.com/

llm:
  model: gpt-3.5-turbo
  llm_supports_functions: true
  context_window: 16385
  temperature: 0

version: 0.2.1  # Profile version (do not modify)
