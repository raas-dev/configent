# See: https://github.com/sigoden/aichat/blob/main/config.example.yaml

# ---- llm ----
model: gemini:gemini-exp-1206 # Specify the LLM to use
temperature: 0 # Set default temperature parameter

# ---- behavior ----
save: true # Indicates whether to persist the message
keybindings: vi # Choose keybinding style (emacs, vi)
editor: vim # Specifies the command used to edit input buffer or session. (e.g. vim, emacs, nano).
wrap: auto # Controls text wrapping (no, auto, <max-width>)
wrap_code: false # Enables or disables wrapping of code blocks

# ---- prelude ----
prelude: "role:chat" # Set a default role or session (role:<name>, session:<name>)

# ---- session ----
# Controls the persistence of the session. if true, auto save; if false, not save; if null, asking the user
save_session: false
# Compress session when token count reaches or exceeds this threshold
compress_threshold: 4000
# Text prompt used for creating a concise summary of session message
summarize_prompt: "Summarize the discussion briefly in 200 words or less to use as a prompt for future context."
# Text prompt used for including the summary of the entire session
summary_prompt: "This is a summary of the chat history as a recap: "

# ---- appearance ----
highlight: true # Controls syntax highlighting
light_theme: false # Activates a light color theme when true. env: AICHAT_LIGHT_THEME
# Custom REPL left/right prompts, see https://github.com/sigoden/aichat/wiki/Custom-REPL-Prompt for more details
left_prompt: "{color.green}{?session {?agent {agent}>}{session}{?role /}}{!session {?agent {agent}>}}{role}{?rag @{rag}}{color.cyan}{?session )}{!session >}{color.reset} "
right_prompt: "{color.purple}{?session {?consume_tokens {consume_tokens}({consume_percent}%)}{!consume_tokens {consume_tokens}}}{color.reset}"

# ---- clients ----
clients:
  - type: claude
  - type: gemini
  - type: openai
  - type: openai-compatible
    name: ollama
    api_base: http://127.0.0.1:11434/v1
    models:
      - name: llama3.2-vision:11b
        max_input_tokens: 128000
        supports_function_calling: true
      - name: nomic-embed-text
        type: embedding
        default_chunk_size: 1500
        max_batch_size: 100
